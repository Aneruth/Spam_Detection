{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "from posixpath import abspath\n",
    "import sys,os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "sys.path.insert(0,os.path.join('Code/Preprocess'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow as tf # Adding padding to our dataset (train and test models)\n",
    "import numpy as np\n",
    "from DataPreparation import dataPrepare\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "\n",
    "    def __init__(self,path) -> None:\n",
    "        self.path = path\n",
    "\n",
    "    def getData(self):\n",
    "        \"\"\"Considers the path of the dataset which holds the sparse matrix. With the help of tensorflow we are\n",
    "        creating the padding for our dataset (X_train and X_test).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Tensor data with padding and dataframe\n",
    "        \"\"\"\n",
    "        fetchData = dataPrepare()\n",
    "    \n",
    "        X_train, X_test, y_train, y_test =  fetchData.Vectorizer(self.path)\n",
    "\n",
    "        # Adding the padding to our sparse matrix\n",
    "        X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train.todense())\n",
    "        X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test.todense())\n",
    "\n",
    "        # make training and test sets in torch\n",
    "        x_train = torch.from_numpy(X_train).type(torch.Tensor)\n",
    "        x_test = torch.from_numpy(X_test).type(torch.Tensor)\n",
    "        y_train = torch.from_numpy(y_train.to_numpy()).type(torch.Tensor)\n",
    "        y_test = torch.from_numpy(y_test.to_numpy()).type(torch.Tensor)\n",
    "        \n",
    "        print(f'Size of our y-train dataset is {y_train.size()} and X-train dataset is {x_train.size()}')\n",
    "\n",
    "        return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        \"\"\"LSTM model which takes the following input:\n",
    "                - Input Dimension\n",
    "                - Hidden Layers (Number)\n",
    "                - Total Number of Layers\n",
    "                - Ouput Diemension\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Length of the dataset\n",
    "            hidden_dim (int): Total hidden layer\n",
    "            num_layers (int): Total layers to be present\n",
    "            output_dim (int): Number of output diemension layer\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # https://discuss.pytorch.org/t/why-do-i-get-typeerror-expected-np-ndarray-got-numpy-ndarray-when-i-use-torch-from-numpy-function/37525/3\n",
    "        x = torch.from_numpy(np.asarray(x)).type(torch.Tensor)\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers,tuple(x.size())[0] , self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, tuple(x.size())[0], self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMImplement:\n",
    "\n",
    "    def __init__(self,path, hidden_dim, num_layers, output_dim) -> None:\n",
    "        \"\"\"A cosntructor which takes the path of the dataset, number of hidden dimensions, number of layers and output\n",
    "        diemensions as our parameters. This will plot our accuracy plot and loss plot.\n",
    "\n",
    "        Args:\n",
    "            path (String): Path of our dataset\n",
    "            hidden_dim (int): Total hidden layer\n",
    "            num_layers (int): Total layers to be present\n",
    "            output_dim (int): Number of output diemension layer\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def run(self):\n",
    "        fetchData = dataPrepare()\n",
    "        X_train, X_test, y_train, y_test =  fetchData.Vectorizer(self.path)\n",
    "        \n",
    "        x_train,x_test,y_train,y_test = Data(self.path).getData()\n",
    "        input_dimension = X_train.shape[1]\n",
    "        model = LSTM(input_dim=input_dimension, hidden_dim=self.hidden_dim, output_dim=self.output_dim, num_layers=self.num_layers)\n",
    "\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        # print(f\"Type of X_train {type(X_train)}\")\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        print(model)\n",
    "        print(len(list(model.parameters())))\n",
    "        for i in range(len(list(model.parameters()))):\n",
    "            print(list(model.parameters())[i].size())\n",
    "\n",
    "        num_epochs = 1000\n",
    "        loss_val  = np.zeros(num_epochs)\n",
    "        acc_val  = np.zeros(num_epochs)\n",
    "\n",
    "        for t in range(num_epochs):\n",
    "            # Forward pass\n",
    "            y_train_pred = model(x_train)\n",
    "\n",
    "            loss = loss_fn(y_train_pred, y_train)\n",
    "            if t % 10 == 0 and t !=0:\n",
    "                print(f\"Epoch {t} MSE is {loss.item()}\")\n",
    "            loss_val[t] = loss.item()\n",
    "            \n",
    "            pred = torch.max(y_train_pred, 1)[1].eq(y_train).sum()\n",
    "            # pred = model_accuracy(y_train_pred,y)\n",
    "            if t % 10 == 0 and t !=0:\n",
    "                print(f\"Epoch {t} accuracy(%) is {(100*pred/len(y_train)).item()}\")\n",
    "            \n",
    "            # Zero out gradient, else they will accumulate between epochs\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of our y-train dataset is torch.Size([952]) and X-train dataset is torch.Size([952, 1, 2701])\n",
      "LSTM(\n",
      "  (lstm): LSTM(2701, 28, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=28, out_features=1, bias=True)\n",
      ")\n",
      "18\n",
      "torch.Size([112, 2701])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112])\n",
      "torch.Size([112])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112])\n",
      "torch.Size([112])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112])\n",
      "torch.Size([112])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([112])\n",
      "torch.Size([112])\n",
      "torch.Size([1, 28])\n",
      "torch.Size([1])\n",
      "Epoch 10 MSE is 0.2740251421928406\n",
      "Epoch 10 accuracy(%) is 57.24789810180664\n",
      "Epoch 20 MSE is 0.25053107738494873\n",
      "Epoch 20 accuracy(%) is 57.24789810180664\n",
      "Epoch 30 MSE is 0.24536658823490143\n",
      "Epoch 30 accuracy(%) is 57.24789810180664\n",
      "Epoch 40 MSE is 0.24475184082984924\n",
      "Epoch 40 accuracy(%) is 57.24789810180664\n",
      "Epoch 50 MSE is 0.24481554329395294\n",
      "Epoch 50 accuracy(%) is 57.24789810180664\n",
      "Epoch 60 MSE is 0.2448105663061142\n",
      "Epoch 60 accuracy(%) is 57.24789810180664\n",
      "Epoch 70 MSE is 0.2447798252105713\n",
      "Epoch 70 accuracy(%) is 57.24789810180664\n",
      "Epoch 80 MSE is 0.24475990235805511\n",
      "Epoch 80 accuracy(%) is 57.24789810180664\n",
      "Epoch 90 MSE is 0.24475149810314178\n",
      "Epoch 90 accuracy(%) is 57.24789810180664\n",
      "Epoch 100 MSE is 0.24474847316741943\n",
      "Epoch 100 accuracy(%) is 57.24789810180664\n",
      "Epoch 110 MSE is 0.24474741518497467\n",
      "Epoch 110 accuracy(%) is 57.24789810180664\n",
      "Epoch 120 MSE is 0.24474696815013885\n",
      "Epoch 120 accuracy(%) is 57.24789810180664\n",
      "Epoch 130 MSE is 0.2447468638420105\n",
      "Epoch 130 accuracy(%) is 57.24789810180664\n",
      "Epoch 140 MSE is 0.24474681913852692\n",
      "Epoch 140 accuracy(%) is 57.24789810180664\n",
      "Epoch 150 MSE is 0.2447468340396881\n",
      "Epoch 150 accuracy(%) is 57.24789810180664\n",
      "Epoch 160 MSE is 0.24474681913852692\n",
      "Epoch 160 accuracy(%) is 57.24789810180664\n",
      "Epoch 170 MSE is 0.24474678933620453\n",
      "Epoch 170 accuracy(%) is 57.24789810180664\n",
      "Epoch 180 MSE is 0.24474681913852692\n",
      "Epoch 180 accuracy(%) is 57.24789810180664\n",
      "Epoch 190 MSE is 0.24474677443504333\n",
      "Epoch 190 accuracy(%) is 57.24789810180664\n",
      "Epoch 200 MSE is 0.24474681913852692\n",
      "Epoch 200 accuracy(%) is 57.24789810180664\n",
      "Epoch 210 MSE is 0.24474681913852692\n",
      "Epoch 210 accuracy(%) is 57.24789810180664\n",
      "Epoch 220 MSE is 0.24474678933620453\n",
      "Epoch 220 accuracy(%) is 57.24789810180664\n",
      "Epoch 230 MSE is 0.24474678933620453\n",
      "Epoch 230 accuracy(%) is 57.24789810180664\n",
      "Epoch 240 MSE is 0.2447468489408493\n",
      "Epoch 240 accuracy(%) is 57.24789810180664\n",
      "Epoch 250 MSE is 0.24474678933620453\n",
      "Epoch 250 accuracy(%) is 57.24789810180664\n",
      "Epoch 260 MSE is 0.24474678933620453\n",
      "Epoch 260 accuracy(%) is 57.24789810180664\n",
      "Epoch 270 MSE is 0.24474681913852692\n",
      "Epoch 270 accuracy(%) is 57.24789810180664\n",
      "Epoch 280 MSE is 0.24474681913852692\n",
      "Epoch 280 accuracy(%) is 57.24789810180664\n",
      "Epoch 290 MSE is 0.24474677443504333\n",
      "Epoch 290 accuracy(%) is 57.24789810180664\n",
      "Epoch 300 MSE is 0.24474681913852692\n",
      "Epoch 300 accuracy(%) is 57.24789810180664\n",
      "Epoch 310 MSE is 0.2447468340396881\n",
      "Epoch 310 accuracy(%) is 57.24789810180664\n",
      "Epoch 320 MSE is 0.24474681913852692\n",
      "Epoch 320 accuracy(%) is 57.24789810180664\n",
      "Epoch 330 MSE is 0.24474677443504333\n",
      "Epoch 330 accuracy(%) is 57.24789810180664\n",
      "Epoch 340 MSE is 0.24474677443504333\n",
      "Epoch 340 accuracy(%) is 57.24789810180664\n",
      "Epoch 350 MSE is 0.24474681913852692\n",
      "Epoch 350 accuracy(%) is 57.24789810180664\n",
      "Epoch 360 MSE is 0.24474678933620453\n",
      "Epoch 360 accuracy(%) is 57.24789810180664\n",
      "Epoch 370 MSE is 0.24474681913852692\n",
      "Epoch 370 accuracy(%) is 57.24789810180664\n",
      "Epoch 380 MSE is 0.24474681913852692\n",
      "Epoch 380 accuracy(%) is 57.24789810180664\n",
      "Epoch 390 MSE is 0.24474678933620453\n",
      "Epoch 390 accuracy(%) is 57.24789810180664\n",
      "Epoch 400 MSE is 0.2447468638420105\n",
      "Epoch 400 accuracy(%) is 57.24789810180664\n",
      "Epoch 410 MSE is 0.24474678933620453\n",
      "Epoch 410 accuracy(%) is 57.24789810180664\n",
      "Epoch 420 MSE is 0.24474681913852692\n",
      "Epoch 420 accuracy(%) is 57.24789810180664\n",
      "Epoch 430 MSE is 0.24474678933620453\n",
      "Epoch 430 accuracy(%) is 57.24789810180664\n",
      "Epoch 440 MSE is 0.24474677443504333\n",
      "Epoch 440 accuracy(%) is 57.24789810180664\n",
      "Epoch 450 MSE is 0.24474681913852692\n",
      "Epoch 450 accuracy(%) is 57.24789810180664\n",
      "Epoch 460 MSE is 0.24474681913852692\n",
      "Epoch 460 accuracy(%) is 57.24789810180664\n",
      "Epoch 470 MSE is 0.24474678933620453\n",
      "Epoch 470 accuracy(%) is 57.24789810180664\n",
      "Epoch 480 MSE is 0.24474677443504333\n",
      "Epoch 480 accuracy(%) is 57.24789810180664\n",
      "Epoch 490 MSE is 0.24474678933620453\n",
      "Epoch 490 accuracy(%) is 57.24789810180664\n",
      "Epoch 500 MSE is 0.24474681913852692\n",
      "Epoch 500 accuracy(%) is 57.24789810180664\n",
      "Epoch 510 MSE is 0.24474678933620453\n",
      "Epoch 510 accuracy(%) is 57.24789810180664\n",
      "Epoch 520 MSE is 0.24474678933620453\n",
      "Epoch 520 accuracy(%) is 57.24789810180664\n",
      "Epoch 530 MSE is 0.24474678933620453\n",
      "Epoch 530 accuracy(%) is 57.24789810180664\n",
      "Epoch 540 MSE is 0.24474678933620453\n",
      "Epoch 540 accuracy(%) is 57.24789810180664\n",
      "Epoch 550 MSE is 0.24474681913852692\n",
      "Epoch 550 accuracy(%) is 57.24789810180664\n",
      "Epoch 560 MSE is 0.24474678933620453\n",
      "Epoch 560 accuracy(%) is 57.24789810180664\n",
      "Epoch 570 MSE is 0.24474677443504333\n",
      "Epoch 570 accuracy(%) is 57.24789810180664\n",
      "Epoch 580 MSE is 0.24474681913852692\n",
      "Epoch 580 accuracy(%) is 57.24789810180664\n",
      "Epoch 590 MSE is 0.2447468638420105\n",
      "Epoch 590 accuracy(%) is 57.24789810180664\n",
      "Epoch 600 MSE is 0.24474677443504333\n",
      "Epoch 600 accuracy(%) is 57.24789810180664\n",
      "Epoch 610 MSE is 0.24474677443504333\n",
      "Epoch 610 accuracy(%) is 57.24789810180664\n",
      "Epoch 620 MSE is 0.24474677443504333\n",
      "Epoch 620 accuracy(%) is 57.24789810180664\n",
      "Epoch 630 MSE is 0.2447468638420105\n",
      "Epoch 630 accuracy(%) is 57.24789810180664\n",
      "Epoch 640 MSE is 0.24474681913852692\n",
      "Epoch 640 accuracy(%) is 57.24789810180664\n",
      "Epoch 650 MSE is 0.24474678933620453\n",
      "Epoch 650 accuracy(%) is 57.24789810180664\n",
      "Epoch 660 MSE is 0.2447468638420105\n",
      "Epoch 660 accuracy(%) is 57.24789810180664\n",
      "Epoch 670 MSE is 0.24474678933620453\n",
      "Epoch 670 accuracy(%) is 57.24789810180664\n",
      "Epoch 680 MSE is 0.24474677443504333\n",
      "Epoch 680 accuracy(%) is 57.24789810180664\n",
      "Epoch 690 MSE is 0.24474678933620453\n",
      "Epoch 690 accuracy(%) is 57.24789810180664\n",
      "Epoch 700 MSE is 0.24474677443504333\n",
      "Epoch 700 accuracy(%) is 57.24789810180664\n",
      "Epoch 710 MSE is 0.24474681913852692\n",
      "Epoch 710 accuracy(%) is 57.24789810180664\n",
      "Epoch 720 MSE is 0.24474678933620453\n",
      "Epoch 720 accuracy(%) is 57.24789810180664\n",
      "Epoch 730 MSE is 0.24474677443504333\n",
      "Epoch 730 accuracy(%) is 57.24789810180664\n",
      "Epoch 740 MSE is 0.24474677443504333\n",
      "Epoch 740 accuracy(%) is 57.24789810180664\n",
      "Epoch 750 MSE is 0.24474681913852692\n",
      "Epoch 750 accuracy(%) is 57.24789810180664\n",
      "Epoch 760 MSE is 0.24474678933620453\n",
      "Epoch 760 accuracy(%) is 57.24789810180664\n",
      "Epoch 770 MSE is 0.24474678933620453\n",
      "Epoch 770 accuracy(%) is 57.24789810180664\n",
      "Epoch 780 MSE is 0.24474678933620453\n",
      "Epoch 780 accuracy(%) is 57.24789810180664\n",
      "Epoch 790 MSE is 0.24474678933620453\n",
      "Epoch 790 accuracy(%) is 57.24789810180664\n",
      "Epoch 800 MSE is 0.24474678933620453\n",
      "Epoch 800 accuracy(%) is 57.24789810180664\n",
      "Epoch 810 MSE is 0.24474677443504333\n",
      "Epoch 810 accuracy(%) is 57.24789810180664\n",
      "Epoch 820 MSE is 0.24474678933620453\n",
      "Epoch 820 accuracy(%) is 57.24789810180664\n",
      "Epoch 830 MSE is 0.24474681913852692\n",
      "Epoch 830 accuracy(%) is 57.24789810180664\n",
      "Epoch 840 MSE is 0.24474681913852692\n",
      "Epoch 840 accuracy(%) is 57.24789810180664\n",
      "Epoch 850 MSE is 0.24474677443504333\n",
      "Epoch 850 accuracy(%) is 57.24789810180664\n",
      "Epoch 860 MSE is 0.24474677443504333\n",
      "Epoch 860 accuracy(%) is 57.24789810180664\n",
      "Epoch 870 MSE is 0.24474677443504333\n",
      "Epoch 870 accuracy(%) is 57.24789810180664\n",
      "Epoch 880 MSE is 0.24474678933620453\n",
      "Epoch 880 accuracy(%) is 57.24789810180664\n",
      "Epoch 890 MSE is 0.24474677443504333\n",
      "Epoch 890 accuracy(%) is 57.24789810180664\n",
      "Epoch 900 MSE is 0.24474677443504333\n",
      "Epoch 900 accuracy(%) is 57.24789810180664\n",
      "Epoch 910 MSE is 0.2447468787431717\n",
      "Epoch 910 accuracy(%) is 57.24789810180664\n",
      "Epoch 920 MSE is 0.2447468787431717\n",
      "Epoch 920 accuracy(%) is 57.24789810180664\n",
      "Epoch 930 MSE is 0.24474678933620453\n",
      "Epoch 930 accuracy(%) is 57.24789810180664\n",
      "Epoch 940 MSE is 0.24474678933620453\n",
      "Epoch 940 accuracy(%) is 57.24789810180664\n",
      "Epoch 950 MSE is 0.24474681913852692\n",
      "Epoch 950 accuracy(%) is 57.24789810180664\n",
      "Epoch 960 MSE is 0.24474681913852692\n",
      "Epoch 960 accuracy(%) is 57.24789810180664\n",
      "Epoch 970 MSE is 0.24474681913852692\n",
      "Epoch 970 accuracy(%) is 57.24789810180664\n",
      "Epoch 980 MSE is 0.24474678933620453\n",
      "Epoch 980 accuracy(%) is 57.24789810180664\n",
      "Epoch 990 MSE is 0.24474678933620453\n",
      "Epoch 990 accuracy(%) is 57.24789810180664\n"
     ]
    }
   ],
   "source": [
    "lst = LSTMImplement('YoutubeComplete.csv',28,4,1).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62b984ecf3fa21db91abb9ce3361d5af483ec95077de7660821dc35f86aea7e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
